{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version information\n",
    "\n",
    "This notebook was created using Python 3.10 and the following package versions:\n",
    "\n",
    "- pandas 2.2.1\n",
    "- numpy 1.26.1\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Data\n",
    "\n",
    "Before moving data, we need to get data from US CDC:\n",
    "\n",
    "`wget --mirror --convert-links --adjust-extension --page-requisites --no-parent https://wonder.cdc.gov/nndss/static/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Function to recursively search for HTML files in a directory\n",
    "def find_html_files(directory):\n",
    "    html_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.html'):\n",
    "                html_files.append(os.path.join(root, file))\n",
    "    \n",
    "    # Remove path contains exclude_dir str\n",
    "    \n",
    "    return html_files\n",
    "\n",
    "# Source directory where HTML files are located\n",
    "source_directory = \"./US/wonder.cdc.gov/nndss/static\"\n",
    "destination_directory = './US/AllData'\n",
    "html_files_list = find_html_files(source_directory)\n",
    "\n",
    "# remove end with 'index.html' or web.config.html\n",
    "html_files_list = [x for x in html_files_list if not x.endswith('index.html') and not x.endswith('web.config.html')]\n",
    "\n",
    "# remove path contains annual\n",
    "html_files_list = [x for x in html_files_list if 'annual' not in x]\n",
    "\n",
    "# remove path contains figure or pdf\n",
    "html_files_list = [x for x in html_files_list if 'figure' not in x and 'pdf' not in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from io import StringIO\n",
    "from html.parser import HTMLParser\n",
    "import re\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from text get date information\n",
    "def extract_date_from_title(title):\n",
    "    # Regular expression pattern for matching dates in the specific format\n",
    "    date_pattern = re.compile(r'(\\bJanuary|\\bFebruary|\\bMarch|\\bApril|\\bMay|\\bJune|\\bJuly|\\bAugust|\\bSeptember|\\bOctober|\\bNovember|\\bDecember)\\s+\\d{1,2},\\s+\\d{4}')\n",
    "    # Search for the pattern in the title\n",
    "    match = date_pattern.search(title)\n",
    "    if match:\n",
    "        date_str = match.group(0)\n",
    "        # Convert the date string to a datetime object\n",
    "        date_obj = datetime.strptime(date_str, '%B %d, %Y')\n",
    "        return date_obj\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# HTMLParser subclass for parsing titles\n",
    "class TitleParser(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title = None\n",
    "        self.recording = False\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == 'title':\n",
    "            self.recording = True\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        if self.recording:\n",
    "            self.title = data\n",
    "\n",
    "    def handle_endtag(self, tag):\n",
    "        if tag == 'title':\n",
    "            self.recording = False\n",
    "\n",
    "# Get year and week from file path\n",
    "def get_year_week(file_path):\n",
    "    # Regular expression pattern for matching year and week in the specific format\n",
    "    year_week_pattern = re.compile(r'(\\d{4})-(\\d{2})')\n",
    "    # Search for the pattern in the file path\n",
    "    match = year_week_pattern.search(file_path)\n",
    "    if match:\n",
    "        year = match.group(1)\n",
    "        week = match.group(2)\n",
    "        return year, week\n",
    "    else:\n",
    "        return None, None\n",
    "            \n",
    "# Function to read HTML files and extract data\n",
    "def read_html_files(file_name):\n",
    "    # Read HTML file content\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    # Extract tables using pandas\n",
    "    html_io = StringIO(html_content)\n",
    "    try:\n",
    "        df_list = pd.read_html(html_io)\n",
    "        df = df_list[0] \n",
    "    except ValueError as e:\n",
    "        print(f\"Error reading HTML tables from {file_name}: {e}\")\n",
    "        df = None\n",
    "\n",
    "    # Create parser and extract title\n",
    "    parser = TitleParser()\n",
    "    parser.feed(html_content)\n",
    "    title = parser.title\n",
    "    date = extract_date_from_title(title)\n",
    "    year, week = get_year_week(file_name)\n",
    "\n",
    "    return df, date, year, week\n",
    "\n",
    "# Function to clean data\n",
    "def clean_data(file_name):\n",
    "    df, date, year, week = read_html_files(file_name)\n",
    "    if df is not None:\n",
    "        # get column names\n",
    "        col_names = df.columns.values\n",
    "        df_names = pd.DataFrame(col_names.tolist())\n",
    "        df_names = df_names.drop(0)\n",
    "        df_names = df_names.reset_index()\n",
    "        df_names['index'] = df_names['index']\n",
    "\n",
    "        # replace column names with column number\n",
    "        df.columns = range(df.shape[1])\n",
    "        df = df.melt(id_vars=[0], value_vars=range(1, df.shape[1]), var_name='State', value_name='Cases')\n",
    "        df = df.rename(columns={0: 'Area'})\n",
    "\n",
    "        # Replace - with 0 in Cases column\n",
    "        # df['Cases'] = df['Cases'].replace('-', '0')\n",
    "        # df['Cases'] = df['Cases'].replace('—', '0')\n",
    "        # df['Cases'] = df['Cases'].replace('', '0')\n",
    "        # df['Cases'] = df['Cases'].astype(int)\n",
    "\n",
    "        # add date year and week column\n",
    "        df['Date'] = date\n",
    "        df['Year'] = year\n",
    "        df['Week'] = week\n",
    "        # convert file_name to url\n",
    "        df['URL'] = file_name.replace('./US/', 'https://')\n",
    "\n",
    "        # merge with df_names by index and State\n",
    "        df = pd.merge(df, df_names, left_on='State', right_on='index', how='left')\n",
    "        df = df.rename(columns={0: 'Disease'})\n",
    "        # add column 2 if not present\n",
    "        if 2 not in df.columns:\n",
    "            df[2] = ''\n",
    "        if 3 not in df.columns:\n",
    "            df[3] = ''\n",
    "        if 1 in df.columns:\n",
    "            df = df[['Area', 'Date', 'Year', 'Week', 'Disease', 1, 2, 3, 'Cases', 'URL']]\n",
    "            return df\n",
    "        else:\n",
    "            pass\n",
    "    data = {'Area': [''], 'Date': [date], 'Year': [year], 'Week': [week], 'Disease': [''], 1: [''], 2: [''], 3: [''], 'Cases': ['No Data'], 'URL': [file_name.replace('./US/', 'https://')]}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Week</th>\n",
       "      <th>Disease</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>Cases</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>2017</td>\n",
       "      <td>28</td>\n",
       "      <td>Salmonellosis</td>\n",
       "      <td>Current week</td>\n",
       "      <td>Current week</td>\n",
       "      <td></td>\n",
       "      <td>456</td>\n",
       "      <td>https://wonder.cdc.gov/nndss/static/2017/28/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEW ENGLAND</td>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>2017</td>\n",
       "      <td>28</td>\n",
       "      <td>Salmonellosis</td>\n",
       "      <td>Current week</td>\n",
       "      <td>Current week</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>https://wonder.cdc.gov/nndss/static/2017/28/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Conn.</td>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>2017</td>\n",
       "      <td>28</td>\n",
       "      <td>Salmonellosis</td>\n",
       "      <td>Current week</td>\n",
       "      <td>Current week</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>https://wonder.cdc.gov/nndss/static/2017/28/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maine</td>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>2017</td>\n",
       "      <td>28</td>\n",
       "      <td>Salmonellosis</td>\n",
       "      <td>Current week</td>\n",
       "      <td>Current week</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>https://wonder.cdc.gov/nndss/static/2017/28/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mass.</td>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>2017</td>\n",
       "      <td>28</td>\n",
       "      <td>Salmonellosis</td>\n",
       "      <td>Current week</td>\n",
       "      <td>Current week</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>https://wonder.cdc.gov/nndss/static/2017/28/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Amer. Samoa</td>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>2017</td>\n",
       "      <td>28</td>\n",
       "      <td>Shigellosis</td>\n",
       "      <td>Cum 2016</td>\n",
       "      <td>Cum 2016</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>https://wonder.cdc.gov/nndss/static/2017/28/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>C.N.M.I.</td>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>2017</td>\n",
       "      <td>28</td>\n",
       "      <td>Shigellosis</td>\n",
       "      <td>Cum 2016</td>\n",
       "      <td>Cum 2016</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>https://wonder.cdc.gov/nndss/static/2017/28/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>Guam</td>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>2017</td>\n",
       "      <td>28</td>\n",
       "      <td>Shigellosis</td>\n",
       "      <td>Cum 2016</td>\n",
       "      <td>Cum 2016</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>https://wonder.cdc.gov/nndss/static/2017/28/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>P.R.</td>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>2017</td>\n",
       "      <td>28</td>\n",
       "      <td>Shigellosis</td>\n",
       "      <td>Cum 2016</td>\n",
       "      <td>Cum 2016</td>\n",
       "      <td></td>\n",
       "      <td>17</td>\n",
       "      <td>https://wonder.cdc.gov/nndss/static/2017/28/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>V.I.</td>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>2017</td>\n",
       "      <td>28</td>\n",
       "      <td>Shigellosis</td>\n",
       "      <td>Cum 2016</td>\n",
       "      <td>Cum 2016</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>https://wonder.cdc.gov/nndss/static/2017/28/20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1005 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Area       Date  Year Week        Disease             1  \\\n",
       "0     UNITED STATES 2017-07-15  2017   28  Salmonellosis  Current week   \n",
       "1       NEW ENGLAND 2017-07-15  2017   28  Salmonellosis  Current week   \n",
       "2             Conn. 2017-07-15  2017   28  Salmonellosis  Current week   \n",
       "3             Maine 2017-07-15  2017   28  Salmonellosis  Current week   \n",
       "4             Mass. 2017-07-15  2017   28  Salmonellosis  Current week   \n",
       "...             ...        ...   ...  ...            ...           ...   \n",
       "1000    Amer. Samoa 2017-07-15  2017   28    Shigellosis      Cum 2016   \n",
       "1001       C.N.M.I. 2017-07-15  2017   28    Shigellosis      Cum 2016   \n",
       "1002           Guam 2017-07-15  2017   28    Shigellosis      Cum 2016   \n",
       "1003           P.R. 2017-07-15  2017   28    Shigellosis      Cum 2016   \n",
       "1004           V.I. 2017-07-15  2017   28    Shigellosis      Cum 2016   \n",
       "\n",
       "                 2 3  Cases                                                URL  \n",
       "0     Current week      456  https://wonder.cdc.gov/nndss/static/2017/28/20...  \n",
       "1     Current week        5  https://wonder.cdc.gov/nndss/static/2017/28/20...  \n",
       "2     Current week        1  https://wonder.cdc.gov/nndss/static/2017/28/20...  \n",
       "3     Current week        2  https://wonder.cdc.gov/nndss/static/2017/28/20...  \n",
       "4     Current week        -  https://wonder.cdc.gov/nndss/static/2017/28/20...  \n",
       "...            ... ..   ...                                                ...  \n",
       "1000      Cum 2016        -  https://wonder.cdc.gov/nndss/static/2017/28/20...  \n",
       "1001      Cum 2016        -  https://wonder.cdc.gov/nndss/static/2017/28/20...  \n",
       "1002      Cum 2016        3  https://wonder.cdc.gov/nndss/static/2017/28/20...  \n",
       "1003      Cum 2016       17  https://wonder.cdc.gov/nndss/static/2017/28/20...  \n",
       "1004      Cum 2016        -  https://wonder.cdc.gov/nndss/static/2017/28/20...  \n",
       "\n",
       "[1005 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data('./US/wonder.cdc.gov/nndss/static/2017/28/2017-28-table2M.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_927557/1874626083.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "num_processes = int(0.9 * multiprocessing.cpu_count())\n",
    "with Pool(processes=num_processes) as pool:\n",
    "    results = pool.map(clean_data, html_files_list)\n",
    "final_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# save to csv\n",
    "final_df.to_csv('./US/AllData.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique date\n",
    "yw_df = final_df[['Year', 'Week']].drop_duplicates()\n",
    "# reorder\n",
    "yw_df = yw_df.sort_values(by=['Year', 'Week'])\n",
    "# reset index\n",
    "yw_df = yw_df.reset_index(drop=True)\n",
    "yw_df['value'] = 1\n",
    "# long table to wide table\n",
    "yw_df = yw_df.pivot(index='Year', columns='Week', values='value')\n",
    "# fill na with 0\n",
    "yw_df = yw_df.fillna(0)\n",
    "# save to csv\n",
    "yw_df.to_csv('./US/YearWeek.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Disease contains pertussis\n",
    "pertussis_df = final_df[final_df['Disease'].str.contains('pertussis', case=False)]\n",
    "pertussis_df = pertussis_df[pertussis_df[1].str.contains('Current', case=False)]\n",
    "# filter Area is in Total, United States, UNITED STATES\n",
    "pertussis_df = pertussis_df[pertussis_df['Area'].isin(['Total', 'United States', 'UNITED STATES'])]\n",
    "\n",
    "# Arrange by Year and Week\n",
    "pertussis_df = pertussis_df.sort_values(by=['Year', 'Week'])\n",
    "# save to csv\n",
    "pertussis_df.to_csv('./US/pertussis.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
